<div align="center">
<img src="https://github.com/guilhermerm99/desafio-crawler/blob/main/eu.png" width="175px">
</div>
<h1 align="center">Desafio Crawler - Guilherme Ribeiro</h1>
<h4 align="center">O wCrawler ou web crawler são termos utilizados para definir os algoritmos criados para a coleta de dados de diferentes fontes, também conhecidos por scraper. Resumidamente, os crawlers são robôs rastreadores ou bots desenvolvidos para realizar a varredura em sites, ou outras fontes (como banco de dados digitais), a fim de capturar informações relevantes. Dessa forma, é possível automatizar diversas tarefas de coleta de dados que são feitas manualmente, ao desenvolver um crawler que execute essas tarefas no lugar do ser humano.</h4>

<h3 align="left">
 ## Biblioteca Utlilizada:
- [Selenium 4.4.3](https://pypi.org/project/selenium/)

## Versão do python:
- [Python 3.9.13](https://www.python.org/downloads/release/python-3913/)

## Versão do Chrome WebDriver:
- [ChromeDriver 104.0.5112.79](https://chromedriver.chromium.org/downloads)
 
## Não sabe qual a sua versão do Chrome?
- Clique nos 3 pontinhos no canto superior direito.
- Passe o mouse em cima da opção "Ajuda"
- Clique em "Sobre o Google Chrome"
- A versão se encontra na página que vai abrir.
</h3>

<h3 align="left">Como rodar o projeto?</h4>
<h4 align="left">
## 1º passo:
  - Instalar as versões corretas da biblioteca Selenium, do Python e do chrome webdriver <br>
## 2º passo:
  - Instalar as versões corretas da biblioteca, python e do chrome webdriver
</h3>


