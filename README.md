<div align="center">
<img src="https://github.com/guilhermerm99/desafio-crawler/blob/main/eu.png" width="175px">
</div>
<h1 align="center">Desafio Crawler - Guilherme Ribeiro</h1>
<h4 align="left">O wCrawler ou web crawler são termos utilizados para definir os algoritmos criados para a coleta de dados de diferentes fontes, também conhecidos por scraper. Resumidamente, os crawlers são robôs rastreadores ou bots desenvolvidos para realizar a varredura em sites, ou outras fontes (como banco de dados digitais), a fim de capturar informações relevantes. Dessa forma, é possível automatizar diversas tarefas de coleta de dados que são feitas manualmente, ao desenvolver um crawler que execute essas tarefas no lugar do ser humano.</h4>

<h3 align="left">

## Versão do python:
- [Python 3.9.13](https://www.python.org/downloads/release/python-3913/)

## Versão do Chrome WebDriver:
- [ChromeDriver 104.0.5112.79](https://chromedriver.chromium.org/downloads)
 
 ## Biblioteca Utlilizada:
- [Selenium 4.4.3](https://pypi.org/project/selenium/)
 
## Não sabe qual a sua versão do Chrome?
- Clique nos 3 pontinhos no canto superior direito.
- Passe o mouse em cima da opção "Ajuda"
- Clique em "Sobre o Google Chrome"
- A versão se encontra na página que vai abrir.
</h3>

<h2 align="left">Como rodar o projeto?</h2>

<h3 align="left">
 
 <h3>
1º passo:
  </h3>
 
  <h4>
  - Instalar as versões corretas da biblioteca Selenium, do Python e do chrome webdriver.</h4>
 
 <h3>
2º passo:
  </h3>
 
  <h4>
  - Após realizar o primeiro passo, deve-se deixar o webdrive com a sua versão do Chrome na mesma pasta do main.py.</h4>
 
 <h3>
3º passo:
  </h3>
 
  <h4>
  - Agora é só executar o código!</h4>
  
   <h3>
4º passo:
  </h3>
 
 <h4>
  - Após executar o código, uma janela do Chrome se abrirá e fará todos os passos sozinha até chegar na página desejada, após chegar na página desejada, a janela se fechará e os dados solicitádos serão entregues no console.</h4>

 
</h3>


